
### 1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?

Гибридные вычисления используют одновременно CPU и GPU, распределяя между ними разные части задачи. В отличие от CPU-only или GPU-only подходов, гибридный метод позволяет задействовать сильные стороны обоих устройств: CPU эффективно выполняет последовательные и управляющие операции, а GPU — массово-параллельные вычисления. Это позволяет повысить общую производительность и лучше использовать доступные вычислительные ресурсы.

### 2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?

Распределение вычислений между CPU и GPU целесообразно для задач, которые:

* состоят из независимых этапов или блоков данных;
* содержат как последовательные, так и массово-параллельные вычисления;
* требуют предварительной подготовки данных или постобработки на CPU;
* обрабатывают большие массивы данных с одинаковыми операциями над элементами.

Примеры: обработка сигналов и изображений, численные методы, машинное обучение, научные расчёты.


### 3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?

При синхронной передаче данных CPU ожидает завершения копирования данных между CPU и GPU, и в это время не выполняет другие операции. При асинхронной передаче копирование выполняется параллельно с вычислениями, и CPU или GPU могут продолжать работу, не дожидаясь окончания передачи.


### 4. Почему асинхронная передача данных может повысить производительность программы?

Асинхронная передача данных позволяет перекрывать копирование данных и вычисления. Пока одна часть данных передаётся между CPU и GPU, другая часть может обрабатываться. Это уменьшает простои вычислительных устройств и повышает общую эффективность программы.


### 5. Какие основные функции MPI используются для распределения и сбора данных между процессами?

Основными функциями MPI для распределения и сбора данных являются:

* `MPI_Scatter` и `MPI_Scatterv` — распределение данных между процессами;
* `MPI_Gather` и `MPI_Gatherv` — сбор данных от процессов;
* `MPI_Reduce` — объединение результатов вычислений (например, сумма или максимум);
* `MPI_Barrier` — синхронизация процессов.


### 6. Как количество процессов MPI влияет на время выполнения программы и почему?

Увеличение числа процессов MPI обычно уменьшает время выполнения за счёт параллельной обработки данных. Однако после определённого числа процессов ускорение замедляется или исчезает из-за накладных расходов на обмен данными, синхронизацию и неравномерную загрузку процессов.

### 7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?

Масштабируемость ограничивают:

* задержки и пропускная способность сети;
* накладные расходы на передачу данных между процессами;
* синхронизация и ожидание медленных процессов;
* неравномерное распределение нагрузки;
* последовательные части алгоритма.

### 8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?

Распределённые вычисления оправданы при обработке больших объёмов данных и вычислительно сложных задач, которые хорошо масштабируются и требуют ресурсов нескольких узлов. Они неэффективны для небольших задач, слабо параллелизуемых алгоритмов и случаев, когда накладные расходы на передачу данных превышают выигрыш от параллельного выполнения.
