## **1. Как изменяется время выполнения программы при увеличении количества процессов? Почему?**

При увеличении количества процессов **время выполнения программы сначала уменьшается**, так как вычислительная нагрузка распределяется между несколькими процессами. Каждый процесс обрабатывает меньший объём данных, что ускоряет вычисления.

Однако при дальнейшем увеличении числа процессов **ускорение замедляется или может отсутствовать**, а иногда время выполнения даже увеличивается. Это связано с тем, что возрастает **накладные расходы на обмен данными и синхронизацию процессов** (вызовы `MPI_Scatter`, `MPI_Allgather`, `MPI_Reduce`, `MPI_Bcast`).

Таким образом, существует **оптимальное число процессов**, при котором достигается наилучшее время выполнения программы.

## **2. Какие факторы могут влиять на производительность программы?**

На производительность параллельной MPI-программы влияют следующие факторы:

* **Количество процессов** и их соответствие числу доступных CPU-ядер
* **Объём передаваемых данных** между процессами
* **Частота коммуникаций** (например, частые вызовы `MPI_Allgather`)
* **Баланс нагрузки** между процессами
* **Размер задачи** (малые задачи плохо масштабируются)
* **Задержки сети и пропускная способность памяти**
* **Алгоритмическая сложность** используемого метода

Например, в алгоритме Флойда–Уоршелла значительную часть времени занимают коллективные операции обмена данными между процессами.

## **3. Как можно оптимизировать передачу данных между процессами?**

Передачу данных между процессами можно оптимизировать следующими способами:

* **Уменьшить объём передаваемых данных**, передавая только необходимые элементы
* **Сократить число коммуникаций**, объединяя несколько операций в одну
* Использовать **коллективные операции MPI** (`MPI_Bcast`, `MPI_Allgather`, `MPI_Reduce`), которые оптимизированы внутри MPI-библиотек
* Применять **асинхронные передачи** (`MPI_Isend`, `MPI_Irecv`) для перекрытия вычислений и коммуникаций
* Обеспечить **равномерное распределение данных**, чтобы избежать простоев процессов

## **4. Какие ограничения возникают при работе с большими данными?**

При работе с большими объёмами данных возникают следующие ограничения:

* **Ограничения по памяти**, так как каждая копия данных занимает значительный объём
* **Рост времени коммуникаций**, особенно при использовании операций типа `MPI_Allgather`
* **Ограниченная масштабируемость**, когда увеличение числа процессов не даёт ускорения
* **Увеличение накладных расходов на синхронизацию**
* **Проблемы с кэш-памятью и пропускной способностью памяти**

В частности, для алгоритма Флойда–Уоршелла сложность по памяти и времени составляет (O(N^2)) и (O(N^3)), что ограничивает его применение для очень больших графов.
