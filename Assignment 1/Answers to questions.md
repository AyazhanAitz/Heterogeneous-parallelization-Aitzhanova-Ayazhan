##Ответы на контрольные вопросы

---

## 1) Отличие динамического массива от статического массива в C++

### Статический массив

* Размер известен **заранее** (во время компиляции).
* Обычно хранится **в стеке** (stack), если объявлен как `int a[10];`.
* Нельзя “увеличить” размер после создания.
* Память освобождается **автоматически**, когда переменная выходит из области видимости.

**Пример:**

```cpp
int a[5] = {1,2,3,4,5}; // статический массив на 5 элементов
```

### Динамический массив

* Размер можно задать **во время выполнения программы** (например, пользователь вводит `n`).
* Память выделяется в **куче** (heap) через `new`.
* Нужно **самому освобождать** память (`delete[]`).
* Можно создавать очень большие массивы (но ограничено RAM).

**Пример:**

```cpp
int n;
cin >> n;
int* arr = new int[n];  // динамический массив
// ...
delete[] arr;           // обязательно нужно освобождать память
```

---

## 2) Что такое указатель и зачем он при динамической памяти?

**Указатель** — это переменная, которая хранит **адрес** в памяти (где лежит значение).

Когда мы создаем переменную с `new`, мы получаем адрес выделенной области памяти. Этот адрес надо где-то хранить — для этого и нужен указатель.

**Пример:**

```cpp
int* p = new int; // выделили память под одно int
*p = 10;          // записали 10 по адресу p
delete p;         // освободили
```

Для массива:

```cpp
int* arr = new int[3];
arr[0] = 5; // то же самое, что *(arr + 0)
delete[] arr;
```

**Указатель нужен для того, чтобы:**

* хранить адрес выделенной памяти;
* обращаться к элементам массива;
* передавать массив/память в функции.

---

## 3) Почему важно корректно освобождать память?

Если не сделать `delete` / `delete[]`, возникает **утечка памяти (memory leak)**:

* программа “теряет” ссылку на выделенную память;
* память остаётся занята до завершения программы;
* при долгой работе/циклах программа может начать тормозить или упасть.


---

## 4) Разница между последовательной и параллельной обработкой массива

### Последовательная обработка

* Один поток (один “работник”) проходит массив от начала до конца.
* Проще отлаживать и предсказуемо.

**Пример:**

```cpp
long long sum = 0;
for (int i = 0; i < n; i++) sum += arr[i];
```

### Параллельная обработка

* Несколько потоков делят работу: каждый считает часть массива.
* Быстрее **на больших данных**, но есть накладные расходы.

Условно:

* Поток 1 суммирует `0..24999`
* Поток 2 суммирует `25000..49999`
* Потом складываем результаты.

---

## 5) Что делает директива `#pragma omp parallel for`?

Она говорит компилятору:

* “вот этот `for` можно распараллелить”
* раздать итерации цикла **между потоками**

**Пример:**

```cpp
#pragma omp parallel for
for (int i = 0; i < n; i++) {
    arr[i] = arr[i] * 2;
}
```

То есть разные потоки одновременно обрабатывают разные `i`.

Важно: цикл должен быть таким, чтобы итерации **не мешали друг другу** (без конфликтов по данным).

---

## 6) Для чего используется `reduction` в OpenMP?

`reduction` нужен, когда несколько потоков должны безопасно “слить” результаты в одну переменную (сумма, максимум, минимум и т.д.)

Идея такая:

* каждому потоку даётся **своя локальная копия** переменной `sum`
* каждый поток считает в свою `sum`
* в конце OpenMP **объединяет** все локальные суммы в одну общую

**Пример суммы:**

```cpp
long long sum = 0;

#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < n; i++) {
    sum += arr[i];
}
```

---

## 7) Почему при параллельной сумме нужен `reduction`, а не обычная переменная?

Если просто написать так:

```cpp
long long sum = 0;

#pragma omp parallel for
for (int i = 0; i < n; i++) {
    sum += arr[i]; // ПРОБЛЕМА
}
```

то возникнет **гонка данных (race condition)**:

* несколько потоков одновременно читают старое значение `sum`
* одновременно прибавляют
* одновременно записывают обратно
* часть прибавлений “теряется”

Пример на пальцах:

* `sum = 100`
* поток A хочет +5, поток B хочет +7
* оба прочитали 100
* A записал 105
* B записал 107
* итог 107 вместо 112

`reduction` решает это автоматически и эффективно.

(Альтернатива — `atomic` или `critical`, но обычно это медленнее для суммирования.)

---

## 8) Почему параллельная версия может быть медленнее последовательной?

Параллельность не всегда = быстрее. Частые причины:

1. **Маленький объём работы**

* Если `n` маленький, то время на создание/управление потоками больше, чем польза.

2. **Накладные расходы на потоки**

* Запуск потоков, планирование, синхронизация — это всё стоит времени.

3. **Синхронизация и блокировки**

* Если часто используются `critical/atomic`, потоки начинают “стоять в очереди”.

4. **Плохая локальность памяти / кэш**

* Потоки могут мешать друг другу в кэше CPU, особенно если доступ к памяти хаотичный.

5. **Ограничение по памяти (memory bandwidth)**

* Бывает, что CPU может считать быстрее, чем память успевает отдавать данные.
* Тогда добавление потоков почти не ускоряет.

6. **Неравномерное распределение работы**

* Один поток получает больше работы, другие простаивают.

7. **Ложное совместное использование (false sharing)**

* Потоки пишут в разные переменные, но они лежат рядом в одной кэш-линии — из-за этого кэш постоянно “дергается”.

8. **Число потоков больше, чем ядер**

* Потоки начинают переключаться (context switching), и это замедляет.

---

