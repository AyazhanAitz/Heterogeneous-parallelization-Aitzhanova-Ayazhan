## 1. В чём отличие измерения времени выполнения от профилирования?

Измерение времени выполнения показывает сколько времени заняла программа или её часть (например, общее время, время функции, время ядра). Оно отвечает на вопрос "быстро или медленно?".

Профилирование показывает почему именно так долго выполняется программа: какие функции, участки кода или операции потребляют больше всего времени, где возникают простои, ожидания и синхронизации. Оно отвечает на вопрос "где именно узкое место?".

## 2. Какие виды узких мест характерны для CPU, GPU и распределённых программ?

### CPU-программы

* ограничение по **числу ядер**;
* **кэш-промахи** и низкая локальность данных;
* **синхронизация потоков** (mutex, lock, barrier);
* ветвления и плохая векторизация.

### GPU-программы

* **пропускная способность памяти** (memory-bound kernels);
* **некоалесцированный доступ** к глобальной памяти;
* низкая **occupancy** (плохой выбор размеров блоков);
* частые передачи данных **CPU ↔ GPU**.

### Распределённые (MPI) программы

* **латентность и пропускная способность сети**;
* дорогие **коллективные операции** (Reduce, Allreduce);
* дисбаланс нагрузки между процессами;
* частые синхронизации (`MPI_Barrier`).

## 3. Почему увеличение числа потоков или процессов не всегда приводит к ускорению?

Потому что:

* существует последовательная часть программы, которую нельзя распараллелить;
* растут накладные расходы на синхронизацию и коммуникации;
* процессы/потоки начинают конкурировать за общие ресурсы (CPU, кэш, память, сеть);
* при oversubscribe происходит частое переключение контекста.

## 4. Как законы Амдала и Густафсона применяются при анализе масштабируемости?

### Закон Амдала

Оценивает **strong scaling** (фиксированный размер задачи).

Показывает, что даже маленькая последовательная часть:

* жёстко ограничивает **максимальное ускорение**,
* объясняет насыщение speedup при росте числа потоков.

Используется, когда:

* задача одного и того же размера,
* анализируется предел ускорения.

### Закон Густафсона

Оценивает **weak scaling** (размер задачи растёт с числом процессов).

Показывает, что:

* при увеличении объёма работы параллельная часть доминирует,
* масштабируемость может быть почти линейной.

Используется, когда:

* задача масштабируется вместе с ресурсами,
* анализируется эффективность при росте problem size.

## 5. Какие факторы наиболее критичны для производительности гибридных приложений (CPU + GPU)?

Ключевые факторы:

1. **Передача данных между CPU и GPU**
   Частые или синхронные копирования (`cudaMemcpy`) могут полностью “съесть” выигрыш от GPU.

2. **Перекрытие вычислений и копирования**
   Использование `cudaMemcpyAsync` и CUDA streams позволяет скрыть латентность.

3. **Баланс нагрузки CPU и GPU**
   Если одна сторона простаивает — гибридность теряет смысл.

4. **Организация памяти**
   Pinned memory, coalesced access, shared memory существенно влияют на производительность.

5. **Минимизация синхронизаций**
   Лишние `cudaDeviceSynchronize()` и блокировки резко снижают масштабируемость.

