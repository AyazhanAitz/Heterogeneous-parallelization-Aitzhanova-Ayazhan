### **1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?**

В архитектуре CUDA существуют глобальная, разделяемая, локальная, регистровая и константная память.
Самой быстрой является регистровая память, так как она расположена непосредственно в потоках. Разделяемая память тоже очень быстрая и используется потоками одного блока. Глобальная память самая медленная, так как находится вне вычислительных блоков GPU. Константная память используется для данных, которые не изменяются, и может работать быстрее глобальной при правильном доступе.

### **2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?**

Разделяемая память позволяет ускорить программу в тех случаях, когда одни и те же данные используются несколькими потоками одного блока. В этом случае данные можно один раз загрузить из глобальной памяти в разделяемую, а затем многократно использовать. Это уменьшает количество обращений к глобальной памяти и повышает производительность.

### **3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?**

Если потоки одного варпа обращаются к последовательным адресам памяти, то доступ считается коалесцированным и выполняется быстрее. Если же потоки обращаются к памяти с большим шагом или вразнобой, то доступ становится некоалесцированным, из-за чего увеличивается количество транзакций памяти и время выполнения программы.

### **4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?**

Потому что производительность GPU сильно зависит от работы с памятью. Даже если вычисления одинаковые, разные способы обращения к памяти могут по-разному загружать шину памяти и кэш. В результате один и тот же алгоритм может выполняться быстрее или медленнее в зависимости от того, как именно данные читаются и записываются.

### **5. Как размер блока потоков влияет на производительность CUDA-ядра?**

Размер блока потоков влияет на то, насколько эффективно используются вычислительные ресурсы GPU. Слишком маленький блок может приводить к плохой загрузке мультипроцессоров, а слишком большой — к нехватке регистров или разделяемой памяти. Обычно оптимальный размер блока подбирается экспериментально и часто равен 128 или 256 потокам.

### **6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?**

Варп — это группа из 32 потоков, которые выполняются одновременно на GPU. Если потоки внутри варпа выполняют разные ветки кода или обращаются к памяти неэффективно, производительность снижается. Поэтому при разработке CUDA-программ важно писать код так, чтобы потоки одного варпа выполняли одинаковые инструкции и имели коалесцированный доступ к памяти.

### **7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?**

При выборе конфигурации сетки и блоков нужно учитывать размер обрабатываемых данных, возможности видеокарты, количество регистров и объём разделяемой памяти, используемых ядром. Также важно учитывать, чтобы количество потоков было кратно размеру варпа, и чтобы GPU был достаточно загружен.

### **8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?**

Потому что во многих CUDA-программах основным узким местом является не вычисление, а доступ к памяти. Даже хороший алгоритм может работать медленно при неэффективном обращении к памяти. Поэтому сначала оптимизируют доступ к памяти, а уже потом, при необходимости, меняют сам алгоритм.
