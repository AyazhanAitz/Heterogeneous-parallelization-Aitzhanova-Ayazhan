## Что такое гетерогенная параллелизация

**Гетерогенная параллелизация** — это подход к вычислениям, при котором в одной программе **одновременно используются разные типы вычислительных устройств**, чаще всего **CPU (центральный процессор)** и **GPU (графический процессор)**.
Каждый тип процессора выполняет **те задачи, для которых он лучше всего подходит**.

Идея гетерогенной параллелизации заключается в том, что:

* **CPU** управляет программой, логикой, вводом-выводом и сложными ветвлениями;
* **GPU** выполняет массовые параллельные вычисления над большими объёмами данных.

Таким образом, программа работает быстрее и эффективнее, чем при использовании только CPU или только GPU.

## Различия между параллельными вычислениями на CPU и GPU

### Параллельные вычисления на CPU

CPU содержит **небольшое количество мощных ядер** (обычно от 4 до 16), каждое из которых:

* хорошо справляется со сложной логикой;
* эффективно выполняет задачи с ветвлениями (if/else);
* быстро работает с небольшими объёмами данных.

**CPU-параллелизм** чаще всего реализуется с помощью:

* потоков (threads);
* библиотек и технологий, таких как **OpenMP**, **pthreads**, **TBB**.

**Пример задачи для CPU**:
обработка бизнес-логики, работа с базами данных, управление программой, выполнение алгоритмов с большим количеством условий.

---

### Параллельные вычисления на GPU

GPU состоит из **тысяч простых вычислительных ядер**, которые:

* выполняют одну и ту же операцию над разными данными;
* работают по модели *SIMD / SIMT* (одна инструкция — много данных);
* менее эффективны при сложных ветвлениях, но очень быстры при однотипных операциях.

**GPU-параллелизм** используется, когда нужно:

* обработать большие массивы данных;
* выполнить одну и ту же операцию для миллионов элементов.

GPU-программирование реализуется с помощью:

* **CUDA** (NVIDIA);
* **OpenCL**;
* **HIP**, **SYCL** и др.

**Пример задачи для GPU**:
сортировка больших массивов, умножение матриц, обработка изображений и видео.

## Преимущества гетерогенной параллелизации

1. **Максимальная производительность**
   Каждая задача выполняется на том устройстве, где она работает быстрее всего.

2. **Рациональное использование ресурсов**
   CPU и GPU не простаивают, а работают совместно.

3. **Ускорение вычислений**
   Многие задачи (сортировка, фильтрация, обработка сигналов) выполняются на GPU в десятки и сотни раз быстрее.

4. **Масштабируемость**
   Можно увеличивать объём данных без пропорционального увеличения времени выполнения.

5. **Энергоэффективность**
   GPU часто выполняет массовые вычисления с меньшими затратами энергии на одну операцию.

## Примеры реальных приложений гетерогенной параллелизации

### 1. Машинное обучение и искусственный интеллект

В системах машинного обучения:

* **CPU** подготавливает данные, управляет обучением модели;
* **GPU** выполняет обучение нейронных сетей (матричные операции).

**Примеры**:

* TensorFlow
* PyTorch
* ChatGPT и другие LLM-модели

---

### 2. Обработка изображений и видео

При обработке изображений:

* **CPU** управляет загрузкой файлов и логикой программы;
* **GPU** выполняет фильтрацию, масштабирование, распознавание объектов.

**Примеры**:

* Adobe Photoshop
* Adobe Premiere Pro
* NVIDIA Video Codec SDK

---

### 3. Научные и инженерные вычисления

В научных расчётах:

* **CPU** управляет алгоритмом и обработкой результатов;
* **GPU** выполняет сложные численные вычисления.

**Примеры**:

* моделирование климата;
* молекулярная динамика;
* расчёты в физике и химии.

---

### 4. Компьютерные игры и графика

В играх:

* **CPU** отвечает за физику, AI, логику игры;
* **GPU** рендерит графику и спецэффекты.

**Примеры**:

* игровые движки (Unreal Engine, Unity);
* современные 3D-игры.

