## 1. Что понимается под гетерогенной параллелизацией?

**Гетерогенная параллелизация** — это подход к вычислениям, при котором **в одной программе используются разные вычислительные устройства**, чаще всего **CPU и GPU**, которые работают совместно.

Идея состоит в том, что:

* **CPU** выполняет управляющую логику, последовательные участки кода, ввод-вывод;
* **GPU** выполняет массовые параллельные вычисления над большими массивами данных.

В таких системах CPU и GPU **не заменяют друг друга**, а **дополняют**.
Примером гетерогенной параллелизации является программа, где:

* CPU с помощью **OpenMP** распараллеливает часть задач;
* GPU с помощью **CUDA** выполняет наиболее тяжёлые вычисления.

---

## 2. В чём принципиальные различия архитектур CPU и GPU?

### Архитектура CPU

* Небольшое количество мощных ядер (обычно 4–16);
* Сложные механизмы управления потоком выполнения;
* Большие кэши;
* Высокая производительность на одну нить.

CPU хорошо подходит для:

* сложной логики;
* алгоритмов с большим количеством условий;
* задач управления программой.

---

### Архитектура GPU

* Тысячи простых вычислительных ядер;
* Модель выполнения *SIMT* (одна инструкция - много потоков);
* Высокая пропускная способность памяти;
* Минимальные кэши и упрощённая логика.

GPU ориентирован на:

* массовую обработку данных;
* выполнение одинаковых операций над большими массивами.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

### Задачи для GPU:

* сортировка больших массивов;
* умножение матриц;
* обработка изображений и видео;
* машинное обучение и нейронные сети;
* численные методы и моделирование.

**Общий признак**:
одинаковая операция выполняется над большим количеством данных.

---

### Задачи для CPU:

* управление программой;
* ввод-вывод данных;
* сложные алгоритмы с большим количеством условий;
* работа с базами данных;
* последовательные части алгоритмов.

---

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

OpenMP предназначен для **параллелизма на CPU**, но он имеет ограничения.

Основные причины:

1. **Зависимости по данным** - результат одной итерации зависит от другой.
2. **Малая вычислительная нагрузка** - накладные расходы превышают пользу.
3. **Сложная логика и ветвления** - снижают эффективность параллелизма.
4. **Последовательные участки кода** (закон Амдала).

Пример:
алгоритмы, где каждый шаг зависит от предыдущего, плохо масштабируются в OpenMP.

---

## 5. В чём заключается основная идея алгоритма сортировки слиянием?

**Сортировка слиянием (Merge Sort)** — это алгоритм типа *разделяй и властвуй*.

Основные шаги:

1. Массив рекурсивно делится на две части.
2. Каждая часть сортируется независимо.
3. Отсортированные части сливаются в один массив.

Преимущества:

* гарантированная сложность **O(n log n)**;
* хорошо поддаётся параллелизации на этапах сортировки и слияния.

---

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

При переносе merge sort на GPU возникают следующие сложности:

1. **Параллельное слияние**
   Слияние двух массивов — не тривиальная задача для GPU, так как требуется
   определить позицию каждого элемента.

2. **Управление памятью**
   Нужно эффективно использовать:

   * global memory;
   * shared memory;
   * ping-pong буферы.

3. **Синхронизация потоков**
   Неправильная синхронизация может привести к race condition.

4. **Выбор размера чанков**
   Слишком маленькие чанки → накладные расходы;
   слишком большие → нехватка ресурсов блока.

---

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

Размер блока и сетки напрямую влияет на:

* загрузку GPU;
* количество одновременно выполняемых потоков;
* использование shared memory и регистров.

### Если блок слишком маленький:

* GPU недозагружен;
* низкая производительность.

### Если блок слишком большой:

* недостаточно ресурсов на SM;
* уменьшается количество активных блоков.

Правильный выбор:

* обычно **128–256 потоков в блоке**;
* размер сетки рассчитывается так, чтобы покрыть все элементы данных.

---

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

Гетерогенный подход эффективнее, потому что:

1. **Каждый тип процессора выполняет свои сильные задачи**

   * CPU — логика и управление;
   * GPU — массовые вычисления.

2. **Снижается общее время выполнения программы**

3. **Лучше используется аппаратное обеспечение**

4. **Повышается масштабируемость**

Использование только CPU не позволяет эффективно обрабатывать большие массивы данных,
а использование только GPU затруднено из-за сложной логики и управления.

